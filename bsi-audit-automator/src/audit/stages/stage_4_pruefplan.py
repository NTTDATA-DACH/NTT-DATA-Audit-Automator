# src/audit/stages/stage_4_pruefplan.py
import logging
import json
import asyncio
from typing import Dict, Any
from google.cloud.exceptions import NotFound

from src.config import AppConfig
from src.clients.gcs_client import GcsClient
from src.clients.ai_client import AiClient
from src.clients.rag_client import RagClient

class Chapter4Runner:
    """
    Handles generating the audit plan for Chapter 4 "Erstellung eines Prüfplans".
    It uses the ground-truth system map (generated by Chapter 3) to create a realistic
    and accurate audit plan.
    """
    STAGE_NAME = "Chapter-4"
    PROMPT_CONFIG_PATH = "assets/json/prompt_config.json"
    GROUND_TRUTH_MAP_PATH = "output/results/intermediate/system_structure_map.json"


    def __init__(self, config: AppConfig, gcs_client: GcsClient, ai_client: AiClient, rag_client: RagClient):
        self.config = config
        self.gcs_client = gcs_client
        self.ai_client = ai_client
        self.rag_client = rag_client
        self.prompt_config = self._load_asset_json(self.PROMPT_CONFIG_PATH)
        self.subchapter_definitions = self._load_subchapter_definitions()
        self.ground_truth_map = None
        logging.info(f"Initialized runner for stage: {self.STAGE_NAME}")

    def _load_asset_json(self, path: str) -> dict:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _load_ground_truth_map(self) -> None:
        """Loads the ground truth system structure map from GCS."""
        try:
            self.ground_truth_map = self.gcs_client.read_json(self.GROUND_TRUTH_MAP_PATH)
            logging.info(f"Successfully loaded ground truth map for Chapter 4 planning.")
        except NotFound:
            logging.warning(f"Ground truth map not found at '{self.GROUND_TRUTH_MAP_PATH}'. Audit plan will be less accurate.")
            self.ground_truth_map = {} # Ensure it's not None
        except Exception as e:
            logging.error(f"Failed to load or parse ground truth map: {e}", exc_info=True)
            self.ground_truth_map = {}

    def _load_subchapter_definitions(self) -> Dict[str, Any]:
        """
        Loads definitions for all Chapter 4 subchapters from the central prompt config.
        The logic for which Baustein selection to run is now based on the AUDIT_TYPE.
        """
        logging.info(f"Loading Chapter 4 definitions for audit type: {self.config.audit_type}")
        definitions = {}
        ch4_config = self.prompt_config["stages"]["Chapter-4"]

        # AI-driven Baustein selection, conditional on the specific audit type
        if self.config.audit_type == "Zertifizierungsaudit":
            logging.info("Loading definitions for 'Zertifizierungsaudit'.")
            definitions["auswahlBausteineErstRezertifizierung"] = ch4_config["auswahlBausteineErstRezertifizierung"]
        elif self.config.audit_type == "1. Überwachungsaudit":
            logging.info("Loading definitions for '1. Überwachungsaudit'.")
            definitions["auswahlBausteine1Ueberwachungsaudit"] = ch4_config["auswahlBausteine1Ueberwachungsaudit"]
        elif self.config.audit_type == "2. Überwachungsaudit":
            logging.info("Loading definitions for '2. Überwachungsaudit'.")
            definitions["auswahlBausteine2Ueberwachungsaudit"] = ch4_config["auswahlBausteine2Ueberwachungsaudit"]
        else:
            logging.warning(f"Unknown audit type '{self.config.audit_type}'. No Baustein selection definitions loaded.")
            
        # Common parts for all audit types
        definitions["auswahlStandorte"] = {
            "key": "4.1.4",
            "type": "deterministic",
            "table": {
                "rows": [{"Standort": "Hauptstandort", "Erst- bzw. Rezertifizierung": "Ja", "1. Überwachungsaudit": "Ja", "2. Überwachungsaudit": "Ja", "Begründung für die Auswahl": "Zentraler Standort mit kritischer Infrastruktur."}]
            }
        }
        definitions["auswahlMassnahmenAusRisikoanalyse"] = ch4_config["auswahlMassnahmenAusRisikoanalyse"]

        # Mark the type for processing
        for key in definitions:
            if "prompt" in definitions[key]:
                definitions[key]["type"] = "ai_driven"

        return definitions

    async def _process_single_subchapter(self, name: str, definition: dict) -> Dict[str, Any]:
        """Generates planning content for a single subchapter, supporting AI and deterministic modes."""
        logging.info(f"Starting planning for subchapter: {definition.get('key', name)} ({name})")
        
        if definition.get("type") == "deterministic":
            logging.info(f"Processing '{name}' deterministically.")
            return {name: {"table": definition["table"]}}

        # AI-driven
        prompt_template = definition["prompt"]
        # FIXED: Use safe string replacement to avoid JSON key conflicts with format()
        ground_truth_json_str = json.dumps(self.ground_truth_map, indent=2, ensure_ascii=False)
        prompt = prompt_template.replace("{ground_truth_map_json}", ground_truth_json_str)
        
        schema = self._load_asset_json(definition["schema_path"])
        
        # Check if this task needs document context
        gcs_uris = []
        source_categories = definition.get("source_categories")
        if source_categories:
            logging.info(f"Loading document context for categories: {source_categories}")
            gcs_uris = self.rag_client.get_gcs_uris_for_categories(source_categories)
        
        try:
            generated_data = await self.ai_client.generate_json_response(
                prompt=prompt,
                json_schema=schema,
                gcs_uris=gcs_uris,
                request_context_log=f"Chapter-4: {name}"
            )
            logging.info(f"Successfully generated plan for subchapter {definition.get('key', name)}")
            # The AI response is the table content itself, e.g. {"rows": [...]}.
            return {name: generated_data}
        except Exception as e:
            logging.error(f"Failed to generate plan for subchapter {definition.get('key', name)}: {e}", exc_info=True)
            return {name: {"rows": []}} # Return empty structure on failure

    async def run(self, force_overwrite: bool = False) -> dict:
        """
        Executes the planning logic for all of Chapter 4 in parallel.
        """
        logging.info(f"Executing stage: {self.STAGE_NAME}")

        # Load the map first, it's a dependency for the prompts
        self._load_ground_truth_map()

        if not self.subchapter_definitions:
            logging.warning(f"No subchapter definitions found. Skipping Chapter 4.")
            return {}

        tasks = [self._process_single_subchapter(name, definition) for name, definition in self.subchapter_definitions.items()]
        results_list = await asyncio.gather(*tasks)

        aggregated_results = {}
        for res_dict in results_list:
            aggregated_results.update(res_dict)
            
        logging.info(f"Successfully aggregated planning results for stage {self.STAGE_NAME}")
        return aggregated_results